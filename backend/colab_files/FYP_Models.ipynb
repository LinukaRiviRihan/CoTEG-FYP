{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V5E1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install \"torch>=2.5.0\" \"torch_xla[tpu]>=2.5.0\" -f https://storage.googleapis.com/libtpu-releases/index.html -q\n",
    "!pip install transformers datasets scikit-learn accelerate seaborn matplotlib -q\n",
    "\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, hamming_loss, jaccard_score, precision_recall_curve\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DEVICE = xm.xla_device()\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "MAX_LEN = 128\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "HIDDEN_DIM = 768\n",
    "\n",
    "# --- DATA LOADING ---\n",
    "print(\"\\n1. Loading GoEmotions Dataset...\")\n",
    "\n",
    "dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "emotion_labels = dataset[\"train\"].features[\"labels\"].feature.names\n",
    "num_labels = len(emotion_labels)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(example):\n",
    "    vec = [0.0] * num_labels\n",
    "    for label in example[\"labels\"]:\n",
    "        vec[label] = 1.0\n",
    "\n",
    "    tokenized = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "    example[\"input_ids\"] = tokenized[\"input_ids\"]\n",
    "    example[\"attention_mask\"] = tokenized[\"attention_mask\"]\n",
    "    example[\"label_vector\"] = vec\n",
    "    return example\n",
    "\n",
    "print(\"\\n2. Preprocessing data...\")\n",
    "\n",
    "dataset = dataset.map(preprocess, remove_columns=[\"text\", \"labels\", \"id\"])\n",
    "dataset.set_format(type=\"torch\")\n",
    "train_loader = DataLoader(dataset[\"train\"], batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(dataset[\"validation\"], batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "# Class Weights (Handle Imbalance)\n",
    "all_labels = torch.stack([x[\"label_vector\"] for x in dataset[\"train\"]])\n",
    "pos_counts = all_labels.sum(dim=0)\n",
    "pos_weight = (len(dataset[\"train\"]) - pos_counts) / (pos_counts + 1e-6)\n",
    "pos_weight = pos_weight.to(DEVICE)\n",
    "\n",
    "# --- GRAPH CONSTRUCTION ---\n",
    "print(\"\\n3. Constructing Emotion Correlation Graph...\")\n",
    "\n",
    "occ_count = np.zeros(num_labels)\n",
    "co_mat = np.zeros((num_labels, num_labels))\n",
    "raw_train = load_dataset(\"go_emotions\", \"simplified\")[\"train\"]\n",
    "\n",
    "for ex in raw_train:\n",
    "    idxs = ex[\"labels\"]\n",
    "    for i in idxs:\n",
    "        occ_count[i] += 1\n",
    "        for j in idxs:\n",
    "            if i != j: co_mat[i][j] += 1\n",
    "\n",
    "conditional_prob = co_mat / (occ_count[:, None] + 1e-6)\n",
    "initial_adj_np = conditional_prob + np.eye(num_labels)\n",
    "initial_adj = torch.tensor(initial_adj_np, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "# --- MODEL DEFINITIONS ---\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        self.classifier = nn.Linear(HIDDEN_DIM, num_labels)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        return self.classifier(self.transformer(ids, mask).last_hidden_state[:, 0, :])\n",
    "\n",
    "class CoTEGModel(nn.Module):\n",
    "    def __init__(self, adj):\n",
    "        super().__init__()\n",
    "        self.text_encoder = nn.Module()\n",
    "        self.text_encoder.transformer = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        self.label_embeddings = nn.Embedding(num_labels, HIDDEN_DIM)\n",
    "        self.A = nn.Parameter(adj.clone())\n",
    "        self.gcn = nn.Module()\n",
    "        self.gcn.linear = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
    "        self.gcn.norm = nn.LayerNorm(HIDDEN_DIM)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        text_repr = self.text_encoder.transformer(ids, mask).last_hidden_state[:, 0, :]\n",
    "        curr_A = torch.relu(self.A)\n",
    "        norm_A = curr_A / (curr_A.sum(1, keepdim=True) + 1e-6)\n",
    "        weight_input = self.label_embeddings.weight\n",
    "        gcn_out = self.gcn.norm(torch.relu(norm_A @ self.gcn.linear(weight_input)) + weight_input)\n",
    "        return text_repr @ gcn_out.T\n",
    "\n",
    "print(f\"\\n4. Training and Evaluating Models...\")\n",
    "\n",
    "# --- TRAINING ENGINE ---\n",
    "def train_and_evaluate(model, name, use_graph_loss=False):\n",
    "\n",
    "    print(f\"\\n- Training {name.upper()} Model...\")\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    transformer_params = []\n",
    "    graph_params = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"transformer\" in name or \"text_encoder\" in name:\n",
    "            transformer_params.append(param)\n",
    "        else:\n",
    "            graph_params.append(param)\n",
    "\n",
    "    optimizer = AdamW([\n",
    "        {'params': transformer_params, 'lr': 2e-5},  # Low LR for BERT\n",
    "        {'params': graph_params, 'lr': 1e-3}         # High LR for Graph\n",
    "    ])\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, 0, len(train_loader)*EPOCHS)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        para_loader = pl.ParallelLoader(train_loader, [DEVICE])\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(para_loader.per_device_loader(DEVICE)):\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "            loss = criterion(logits, batch[\"label_vector\"])\n",
    "\n",
    "            if use_graph_loss:\n",
    "                curr_A = torch.relu(model.A)\n",
    "                norm_A = curr_A / (curr_A.sum(1, keepdim=True) + 1e-6)\n",
    "                loss += 0.01 * torch.norm(norm_A - initial_adj, p='fro')\n",
    "\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer)\n",
    "            scheduler.step()\n",
    "            current_loss = loss.item()\n",
    "            total_loss += current_loss\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                print(f\"\\rEpoch {epoch+1} | Step {i+1}/{len(train_loader)} | Loss: {current_loss:.4f}\", end=\"\")\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS} | Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # --- EVALUATION ---\n",
    "    print(f\"\\n- Evaluating {name}...\")\n",
    "    model.eval()\n",
    "\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "    probs_list, trues_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            logits = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "            probs_list.append(torch.sigmoid(logits).numpy())\n",
    "            trues_list.append(batch[\"label_vector\"].numpy())\n",
    "\n",
    "    probs = np.vstack(probs_list)\n",
    "    trues = np.vstack(trues_list)\n",
    "\n",
    "    # Thresholds\n",
    "    thresholds = []\n",
    "    for i in range(num_labels):\n",
    "        p, r, t = precision_recall_curve(trues[:, i], probs[:, i])\n",
    "        if len(t) == 0:\n",
    "            thresholds.append(0.5)\n",
    "            continue\n",
    "\n",
    "        f1 = 2*p*r/(p+r+1e-6)\n",
    "        best_idx = np.argmax(f1)\n",
    "        thresholds.append(t[best_idx] if best_idx < len(t) else 0.5)\n",
    "\n",
    "    preds = np.zeros_like(probs)\n",
    "    for i in range(num_labels):\n",
    "        preds[:, i] = (probs[:, i] > thresholds[i]).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"macro_f1\": float(f1_score(trues, preds, average=\"macro\")),\n",
    "        \"weighted_f1\": float(f1_score(trues, preds, average=\"weighted\")),\n",
    "        \"exact_accuracy\": float(accuracy_score(trues, preds)),\n",
    "        \"hamming_loss\": float(hamming_loss(trues, preds))\n",
    "    }\n",
    "\n",
    "    print(f\"- {name} Metrics: {metrics}\")\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    return model, thresholds, metrics\n",
    "\n",
    "# --- RUN TRAINING ---\n",
    "baseline_model, base_thrs, base_metrics = train_and_evaluate(BaselineModel(), \"Baseline\")\n",
    "coteg_model, coteg_thrs, coteg_metrics = train_and_evaluate(CoTEGModel(initial_adj), \"CoTEG\", use_graph_loss=True)\n",
    "\n",
    "# --- VISUALIZATION ---\n",
    "def predict_emotions(text_input):\n",
    "    print(f\"\\n5. VISUAL ANALYSIS FOR INPUT: \\\"{text_input}\\\"\")\n",
    "\n",
    "    # 1. SETUP\n",
    "    baseline_model.eval().to(\"cpu\")\n",
    "    coteg_model.eval().to(\"cpu\")\n",
    "\n",
    "    # 2. SMART SPLITTING (\"Divide and Conquer\")\n",
    "    # Split by 'but', 'however', or punctuation to isolate conflicting emotions\n",
    "    chunks = re.split(r' but | however |[.!?]+', text_input)\n",
    "    chunks = [c.strip() for c in chunks if len(c) > 5] # Clean up\n",
    "    if not chunks: chunks = [text_input] # Fallback\n",
    "\n",
    "    print(f\"\\n6. Logic: Split input into {len(chunks)} segments: {chunks}\\n\")\n",
    "\n",
    "    # 3. INFERENCE LOOP\n",
    "    # Track the MAXIMUM probability seen for each emotion across all chunks\n",
    "    base_final_probs = np.zeros(num_labels)\n",
    "    coteg_final_probs = np.zeros(num_labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for chunk in chunks:\n",
    "            # Tokenize chunk\n",
    "            tokenized = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=MAX_LEN)\n",
    "            ids = tokenized[\"input_ids\"]\n",
    "            mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "            # Run Inference\n",
    "            base_logits = baseline_model(ids, mask)\n",
    "            coteg_logits = coteg_model(ids, mask)\n",
    "\n",
    "            chunk_base_probs = torch.sigmoid(base_logits)[0].numpy()\n",
    "            chunk_coteg_probs = torch.sigmoid(coteg_logits)[0].numpy()\n",
    "\n",
    "            # Max Pooling\n",
    "            base_final_probs = np.maximum(base_final_probs, chunk_base_probs)\n",
    "            coteg_final_probs = np.maximum(coteg_final_probs, chunk_coteg_probs)\n",
    "\n",
    "    # 4. FILTERING\n",
    "\n",
    "    data = []\n",
    "    for i, label in enumerate(emotion_labels):\n",
    "        if base_final_probs[i] > 0.05 or coteg_final_probs[i] > 0.05:\n",
    "            data.append({\"Emotion\": label, \"Score\": base_final_probs[i], \"Model\": \"Baseline\"})\n",
    "            data.append({\"Emotion\": label, \"Score\": coteg_final_probs[i], \"Model\": \"CoTEG\"})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"No strong emotions detected!\")\n",
    "        return"
   ],
   "metadata": {
    "id": "3RmXSpsMVgob"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "print(\"\\n5. Connecting to Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n6. Saving models to the Drive root folder...\")\n",
    "\n",
    "baseline_model.to(\"cpu\")\n",
    "coteg_model.to(\"cpu\")\n",
    "\n",
    "torch.save({\n",
    "    'state': coteg_model.state_dict(),\n",
    "    'thr': coteg_thrs,\n",
    "    'metrics': coteg_metrics\n",
    "}, \"/content/drive/My Drive/coteg_model.pth\")\n",
    "\n",
    "torch.save({\n",
    "    'state': baseline_model.state_dict(),\n",
    "    'thr': base_thrs,\n",
    "    'metrics': base_metrics\n",
    "}, \"/content/drive/My Drive/baseline_model.pth\")\n",
    "\n",
    "print(\"Models saved successfully!\")"
   ],
   "metadata": {
    "id": "lSaaNpM-VjGj"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
